name: TV EPG

on:
  push:
    paths:
      - 'm_playlist.m3u8'
      - 'd_playlist.m3u8'
  schedule:
    - cron: '0 11 * * *'
  workflow_dispatch:
    inputs:
      no_dashboard:
        description: 'No dashboard commit'
        type: boolean
        default: false

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build_epg:
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    concurrency:
      group: epg-pages
      cancel-in-progress: true
    runs-on: ubuntu-latest
    timeout-minutes: 35
    outputs:
      job_id: ${{ steps.build_step.outputs.job_id }}
    env:
      PER_SITE_JOBS: "10"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Clone iptv-org/epg
        run: git clone --depth 1 https://github.com/iptv-org/epg.git

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "22"
          cache: "npm"
          cache-dependency-path: epg/package-lock.json

      - name: Build EPG
        id: build_step
        shell: bash
        env:
          NODE_OPTIONS: "--max-old-space-size=6000"
          PIPELINE: |
            #!/usr/bin/env bash
            set -euo pipefail
            OUTDIR="${OUTDIR:-$RUNNER_TEMP}"; export OUTDIR

            echo "::group::Install"
            pushd epg >/dev/null
            npm ci --no-audit --no-fund --silent
            popd >/dev/null
            echo "::endgroup::"

            echo "::group::Prepare"
            test -s "${GITHUB_WORKSPACE}/m_channels.xml"
            test -s "${GITHUB_WORKSPACE}/d_channels.xml"
            python - << 'PY'
            import os, json, xml.etree.ElementTree as ET
            gw=os.environ["GITHUB_WORKSPACE"]; outdir=os.environ["OUTDIR"]
            def load_by_site(path):
                r=ET.parse(path).getroot(); mp={}
                for ch in r.findall("channel"):
                    site=(ch.get("site") or "").strip().lower()
                    if site: mp.setdefault(site,[]).append(ch)
                return mp
            m_by=load_by_site(os.path.join(gw,"m_channels.xml"))
            d_by=load_by_site(os.path.join(gw,"d_channels.xml"))
            meta={}
            all_sites=sorted(set(m_by.keys())|set(d_by.keys()))
            os.makedirs(outdir,exist_ok=True)
            for site in all_sites:
                m_list=m_by.get(site,[]); d_list=d_by.get(site,[])
                root=ET.Element("channels"); m_ids=set(); d_ids=set()
                for ch in m_list:
                    root.append(ch)
                    sid=(ch.get("site_id") or "").strip()
                    if sid: m_ids.add(sid)
                for ch in d_list:
                    root.append(ch)
                    sid=(ch.get("site_id") or "").strip()
                    if sid: d_ids.add(sid)
                try: ET.indent(root,space="  ",level=0)
                except: pass
                ET.ElementTree(root).write(
                    os.path.join(outdir,f"_all__{site}.channels.xml"),
                    encoding="utf-8",xml_declaration=True
                )
                meta[site]={"M":sorted(m_ids),"D":sorted(d_ids)}
            for site,info in sorted(meta.items()):
                if info["M"]: print(f"> m {site} : {len(info['M'])} channels")
                if info["D"]: print(f"> d {site} : {len(info['D'])} channels")
            with open(os.path.join(outdir,"site_meta.json"),"w",encoding="utf-8") as f:
                json.dump(meta,f,ensure_ascii=False)
            PY
            echo "::endgroup::"

            cat > "${RUNNER_TEMP}/helpers.sh" <<'BASH'
            set -euo pipefail
            tune_params(){ local s="$1" maxc=6 tout=45000; case "$s" in
              raiplay.it) maxc=8; tout=45000;;
              mediasetinfinity.mediaset.it) maxc=10; tout=40000;;
              guidatv.sky.it) maxc=6; tout=45000;;
              epgshare01.online) maxc=6; tout=45000;;
              tivu.tv|guida.tv) maxc=3; tout=70000;;
            esac; echo "$maxc $tout"; }
            filter_log(){ awk '/^\s*info\s+\[[0-9]+\/[0-9]+\].*\([0-9]+ programs\)/||/saving to/||/^\s*success\s+done/'; }
            throttle(){ local lim="${PER_SITE_JOBS:-10}"; while [ "$(jobs -rp | wc -l)" -ge "$lim" ]; do wait -n || true; done; }
            retry_grab(){
              local ch="$1" site="$2" out="$3" maxc="$4" tout="$5"
              echo "Grab $site -> $out (maxc=$maxc timeout=${tout}ms)"
              SECONDS=0
              try(){ npm run grab -- --channels="$ch" --days=4 --maxConnections="$maxc" --timeout="$tout" --output="$out" | filter_log; }
              if (try) || (sleep 2 && try) || (sleep 4 && try); then
                echo "TIME $site ${SECONDS}s"
                return 0
              else
                echo "TIME $site ${SECONDS}s"
                return 1
              fi
            }
            run_block(){
              local prefix="$1" outdir="$2"
              shopt -s nullglob
              for f in "${OUTDIR}/${prefix}__"*.channels.xml; do
                [ -s "$f" ] || continue
                grep -q '<channel' "$f" || continue
                local site="$(basename "$f")"; site="${site#${prefix}__}"; site="${site%.channels.xml}"
                read MAXC TOUT < <(tune_params "$site")
                local out="${outdir}/${prefix}__${site}.xml"
                throttle; (
                  if retry_grab "$f" "$site" "$out" "$MAXC" "$TOUT"; then
                    echo "OK ${prefix#_} $site -> $out"
                  else
                    echo "FAIL ${prefix#_} $site"; : > "$out"
                  fi
                ) &
              done
              wait || true
            }
            BASH

            echo "::group::Grab"
            pushd epg >/dev/null
            source "${RUNNER_TEMP}/helpers.sh"
            mkdir -p "${OUTDIR}/out-all"
            run_block "_all" "${OUTDIR}/out-all"
            popd >/dev/null
            echo "::endgroup::"

            echo "::group::Merge"
            python - << 'PY'
            import os, glob, json, xml.etree.ElementTree as ET
            gw=os.environ["GITHUB_WORKSPACE"]; temp=os.environ["OUTDIR"]
            meta_path=os.path.join(temp,"site_meta.json")
            if os.path.exists(meta_path):
                with open(meta_path,encoding="utf-8") as f: meta=json.load(f)
            else:
                meta={}
            m_ids=set(); d_ids=set()
            for site,info in meta.items():
                m_ids.update(info.get("M",[])); d_ids.update(info.get("D",[]))
            files=sorted(
                f for f in glob.glob(os.path.join(temp,"out-all","_all__*.xml"))
                if os.path.isfile(f) and os.path.getsize(f)>0
            )
            def ensure_empty(outp):
                with open(outp,"w",encoding="utf-8") as f:
                    f.write('<?xml version="1.0" encoding="UTF-8"?>\\n<tv></tv>')
            if not files:
                ensure_empty(os.path.join(gw,"m_epg.xml"))
                ensure_empty(os.path.join(gw,"d_epg.xml"))
            else:
                t0=ET.parse(files[0]); r0=t0.getroot()
                chs=set(c.get("id","") for c in r0.findall("channel"))
                progs=set((p.get("channel",""), p.get("start","")) for p in r0.findall("programme"))
                for pth in files[1:]:
                    try: r=ET.parse(pth).getroot()
                    except: continue
                    for c in r.findall("channel"):
                        cid=c.get("id","")
                        if cid and cid not in chs:
                            r0.append(c); chs.add(cid)
                    for pr in r.findall("programme"):
                        k=(pr.get("channel",""), pr.get("start",""))
                        if k not in progs:
                            r0.append(pr); progs.add(k)
                try: ET.indent(t0,space="  ",level=0)
                except: pass
                out_m=os.path.join(gw,"m_epg.xml")
                out_d=os.path.join(gw,"d_epg.xml")
                t0.write(out_m,encoding="utf-8",xml_declaration=True)
                t0.write(out_d,encoding="utf-8",xml_declaration=True)
            print(f"m_epg.xml ->  {len(m_ids)} channels")
            print(f"d_epg.xml ->  {len(d_ids)} channels")
            PY
            echo "::endgroup::"

            SITE="${OUTDIR}/site"
            mkdir -p "$SITE"
            cp "${GITHUB_WORKSPACE}/m_epg.xml" "${SITE}/"
            cp "${GITHUB_WORKSPACE}/d_epg.xml" "${SITE}/"
            [ -f "${GITHUB_WORKSPACE}/m_playlist.m3u8" ] && cp "${GITHUB_WORKSPACE}/m_playlist.m3u8" "${SITE}/"
            [ -f "${GITHUB_WORKSPACE}/d_playlist.m3u8" ] && cp "${GITHUB_WORKSPACE}/d_playlist.m3u8" "${SITE}/"
            echo "SITE=${SITE}" >> "$GITHUB_ENV"

        run: |
          set -euo pipefail
          echo "job_id=${{ github.job_id }}" >> "$GITHUB_OUTPUT"
          printf '%s\n' "$PIPELINE" > "$RUNNER_TEMP/pipeline.sh"
          chmod +x "$RUNNER_TEMP/pipeline.sh"
          bash "$RUNNER_TEMP/pipeline.sh" 2>&1 | tee "$GITHUB_WORKSPACE/tv_epg.log"

      - name: Upload log artifact
        uses: actions/upload-artifact@v4
        with:
          name: tv-logs
          path: tv_epg.log
          if-no-files-found: warn
          retention-days: 7

      - name: Upload artifact to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: ${{ env.SITE }}

  deploy_epg:
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    needs: build_epg
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  update_readme:
    if: ${{ github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && (github.event.inputs.no_dashboard != 'true')) }}
    needs:
      - build_epg
      - deploy_epg
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
      RUN_EVENT: ${{ github.event_name }}
      RUN_ID: ${{ github.run_id }}
      GITHUB_REPOSITORY: ${{ github.repository }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      GIT_BRANCH: ${{ github.ref_name }}
      DASH_COMMIT_MSG: 'EPG updated! ðŸ“º'
      TV_LOG: tv_epg.log
      TV_JOB_ID: ${{ needs.build_epg.outputs.job_id }}
      TV_STEP_IDX: 5
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install deps
        run: |
          pip install requests

      - name: Download log artifact
        uses: actions/download-artifact@v4
        with:
          name: tv-logs
          path: .

      - name: Update README (tv section only)
        run: |
          python dashboard.py tv --log "$TV_LOG"

      - name: Commit README (TV EPG)
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add README.md
          git commit -m "$DASH_COMMIT_MSG" || echo "No changes"
          git push || true

  publish_assets:
    if: ${{ github.event_name == 'push' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare site (reuse existing EPG from Pages)
        shell: bash
        run: |
          set -euo pipefail
          OUTDIR="${RUNNER_TEMP}/site"
          mkdir -p "$OUTDIR"
          curl -fsSL "https://dtvabrand.github.io/entertainment/m_epg.xml" -o "$OUTDIR/m_epg.xml" || true
          curl -fsSL "https://dtvabrand.github.io/entertainment/d_epg.xml" -o "$OUTDIR/d_epg.xml" || true
          [ -f "m_playlist.m3u8" ] && cp "m_playlist.m3u8" "$OUTDIR/"
          [ -f "d_playlist.m3u8" ] && cp "d_playlist.m3u8" "$OUTDIR/"
          echo "SITE=$OUTDIR" >> "$GITHUB_ENV"

      - name: Upload artifact to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: ${{ env.SITE }}

  deploy_assets:
    if: ${{ github.event_name == 'push' }}
    needs: publish_assets
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
